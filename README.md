# ğŸ“Š Data Engineer â€“ Jira Ticket Analysis Project

## ğŸ§  Overview

This project demonstrates a **full data engineering pipeline** built around **Jira ticket data**.

It simulates real-world Jira tickets, ingests them from the Jira API, enriches them using **NLP embeddings**, stores structured results in a database, and performs analytical insights such as **technology classification** and **server-level analysis**.

The project is designed with **clear separation of concerns**, async data ingestion, and modular analysis components.

---

## ğŸ¯ Project Goals

* Generate and ingest realistic Jira tickets
* Store structured ticket data in a database
* Create semantic embeddings for text fields
* Classify tickets by technology domain
* Analyze server occurrences in ticket descriptions
* Export analytical results for inspection and visualization
* Follow production-style project structure

---

## ğŸš€ Key Capabilities

* âœ… Async Jira API ingestion (rate-limit aware)
* âœ… Realistic ticket description generation
* âœ… SQLite-based persistence layer
* âœ… Sentence Transformer embeddings (MiniLM)
* âœ… Ticket â†” Technology semantic matching
* âœ… Keyword-enriched cosine similarity
* âœ… Server occurrence analysis using regex
* âœ… CSV export & plot generation
* âœ… Clean, interview-ready architecture

---

## ğŸ—‚ï¸ Project Structure

```
data-enginer/
â”‚
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ cosine_similarity.py      # Ticket â†” Technology matching
â”‚   â”œâ”€â”€ server_analysis.py        # Server statistics & visualization
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ connection.py             # SQLite connection handling
â”‚   â”œâ”€â”€ schema.py                 # CREATE TABLE definitions
â”‚   â”œâ”€â”€ repository.py             # DB read/write logic
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ init_embeddings.py        # Ticket & technology embeddings
â”‚   â”œâ”€â”€ utils.py                  # BLOB â†’ numpy vector helpers
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ technologies.py           # Technology descriptions (domain knowledge)
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ plot_utils.py             # Server counting & plots
â”‚   â”œâ”€â”€ jira_utils.py             # Jira client & async ingestion
â”‚   â”œâ”€â”€ config_utils.py           # Config loading (config.json)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ main.py                       # Pipeline entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“ Folder Responsibilities

### `analysis/`

Contains **pure analysis logic**:

* Cosine similarity computation
* Keyword-based score enrichment
* Server extraction and statistics
* No database writes

> *Think of this as the brain of the system.*

---

### `db/`

Handles **all persistence concerns**:

* SQLite connections
* Table creation
* Insert / update / select operations

> *The storage layer.*

---

### `embeddings/`

Responsible for **NLP representation**:

* SentenceTransformer usage
* Embedding creation
* Vector serialization/deserialization

> *Easily replaceable embedding layer.*

---

### `templates/`

Contains **domain knowledge only**:

* Technology descriptions
* Text templates

> *Human knowledge injected into the system.*

---

### `utils/`

Reusable helpers and infrastructure code:

#### Jira utilities

* Jira client initialization
* Async ticket fetching with pagination
* Rate-limitâ€“safe ingestion

#### Server analysis utilities

* Regex-based server extraction
* Frequency counting
* Bar plot generation (saved to file)

> *Support layer shared across the project.*

---

### `main.py`

The **orchestrator**:

* Runs ingestion
* Triggers embeddings
* Executes analysis
* Exports results

> No heavy logic, only pipeline control.

---

## ğŸ§¬ Technologies Used

* **Python 3**
* **Jira REST API**
* **SQLite**
* **pandas**
* **numpy**
* **matplotlib**
* **sentence-transformers (MiniLM)**

---

## ğŸ“¦ Installation

Create and activate a virtual environment, then install dependencies:

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Running the Project

```bash
python main.py
```

The pipeline will:

1. Connect to Jira
2. Fetch tickets asynchronously
3. Store structured ticket data
4. Create embeddings (if missing)
5. Match tickets to technologies
6. Analyze server occurrences
7. Export results (CSV + plots)

---

## ğŸ§  Ticket â†” Technology Matching

1. Ticket descriptions â†’ embeddings
2. Technology descriptions â†’ embeddings
3. Cosine similarity computation
4. Keyword-based bonus applied
5. Best matching technology selected

> âš ï¸ This is a **ranking system**, not a hard classifier.

---

## ğŸ“Š Outputs

* `ticket_technology_match.csv`
* `server_occurrences.png`
* Similarity scores per ticket
* Structured tables in SQLite

---

## ğŸ§  Design Principles

* Clear separation of concerns
* Async where I/O is involved
* Deterministic and reproducible
* Domain-aware (not â€œML magicâ€)
* Easy to extend and explain

---

## ğŸš€ Possible Extensions

* Top-K technology matching
* Confidence labels (high / medium / low)
* Dashboard (Streamlit / Superset)
* Streaming ingestion
* Migration to PostgreSQL
* Feature store integration

---

## ğŸ“ Summary

This project showcases:

* Practical data engineering skills
* Real-world Jira data ingestion
* NLP-based semantic analysis
* Clean, modular architecture
* Interview-ready design and explanations

